{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Super Resolution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny041tz9ST3g"
      },
      "source": [
        "\n",
        "# Tensorboard for visual logging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc1vfLv5Q5m7",
        "outputId": "d376dc3f-2248-439d-ac61-f2df8de88985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        }
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 3486), started 2:23:39 ago. (Use '!kill 3486' to kill it.)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = await google.colab.kernel.proxyPort(6006, {\"cache\": true});\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6rVbHelSbgo"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzq2QnWhRbBn",
        "outputId": "774d7b07-32c3-4cdf-9209-480c97c2a98a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torchvision, torchvision.transforms as transforms\n",
        "import torch, torch.nn as nn\n",
        "import random, subprocess, os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "\n",
        "# To read and write to google drive\n",
        "drive.mount(\"/content/drive/\")\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDuKFrqzSdkl"
      },
      "source": [
        "# Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v16VY8ymSz54"
      },
      "source": [
        "def load_loader_stl(crop_size: int = 33, batch_size: int = 128, num_workers: int = 1, scale: float = 2.0):\n",
        "    \"\"\"\n",
        "    Loads the dataloader of the STL-10 Dataset using the given specifications with the required\n",
        "                          augmentation schemes\n",
        "    input : crop_size -> image size of the square sub images the model has been trained on\n",
        "            scale     -> Scale by which the low resolution image is downscaled\n",
        "    output: dataloader iterable to be able to train on the images\n",
        "\n",
        "    Augmentation Schemes: Since torch has strong built in support for transforms, augmentation\n",
        "                          was done within our dataloader transforms employing TenCrop on each\n",
        "                          image. For every image we get 5 crops (Center + 4 corners) and the horizontal\n",
        "                          flip of each. TenCrop returns a tuple, which was handled using lambda\n",
        "                          and also in the training script in the cell below.\n",
        "\n",
        "    \"\"\"\n",
        "    # Write transforms for TenCrop and for generating low res images using bicubic interpolation (interpolation = 3)\n",
        "    transform_high_res = transforms.Compose([\n",
        "            transforms.TenCrop(crop_size),\n",
        "            transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
        "        ])\n",
        "    transform_low_res = transforms.Compose([\n",
        "            transforms.Resize(int(96 / scale), interpolation=3),\n",
        "            transforms.Resize(96, interpolation=3),\n",
        "            transform_high_res\n",
        "        ])\n",
        "\n",
        "    # Make STL-10 dataset object\n",
        "    dataset_high_res = torchvision.datasets.STL10('.', transform = transform_high_res, download = True)\n",
        "    dataset_low_res = torchvision.datasets.STL10('.', transform = transform_low_res, download = False)\n",
        "\n",
        "    # Create the dataloader object using the transforms (Not shuffled since we will be checking progress on the same examples)\n",
        "    dataloader_high_res = torch.utils.data.DataLoader(dataset_high_res, batch_size = batch_size, num_workers = num_workers, shuffle = False)\n",
        "    dataloader_low_res = torch.utils.data.DataLoader(dataset_low_res, batch_size = batch_size, num_workers = num_workers, shuffle = False)\n",
        "    return dataloader_low_res, dataloader_high_res"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQi_104rSg7E"
      },
      "source": [
        "# Models used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOXcyN7bR5tJ"
      },
      "source": [
        "class SuperResolution(nn.Module):\n",
        "    \"\"\"\n",
        "    Network Architecture as per specified in the paper.\n",
        "    The chosen configuration for successive filter sizes are 9-5-5\n",
        "    The chosed configuration for successive filter depth are 128-64(-3)\n",
        "    \"\"\"\n",
        "    def __init__(self, sub_image: int = 33, spatial: list = [9, 5, 5], filter: list = [128, 64], num_channels: int = 3):\n",
        "        super().__init__()\n",
        "        self.layer_1 = nn.Conv2d(num_channels, filter[0], spatial[0], padding = spatial[0] // 2)\n",
        "        self.layer_2 = nn.Conv2d(filter[0], filter[1], spatial[1], padding = spatial[1] // 2)\n",
        "        self.layer_3 = nn.Conv2d(filter[1], num_channels, spatial[2], padding = spatial[2] // 2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, image_batch):\n",
        "        x = self.layer_1(image_batch)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer_2(x)\n",
        "        y = self.relu(x)\n",
        "        x = self.layer_3(y)\n",
        "        return x, y"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYT-GdjCSj-k"
      },
      "source": [
        "# Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLzng-oCSEGn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "7c1a2ad9-ad74-48ea-f4ff-49948f71c180"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Define your SuperResolution model (you need to implement this)\n",
        "class SuperResolution(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SuperResolution, self).__init__()\n",
        "        # Add your model layers here\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, padding=4)\n",
        "        self.conv2 = nn.Conv2d(64, 32, kernel_size=1, padding=0)\n",
        "        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, padding=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Example forward pass\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.conv3(x)\n",
        "        return x, x  # Simplified for example\n",
        "\n",
        "# Training function (updated)\n",
        "def train():\n",
        "    # Initialize components\n",
        "    low_res_loader, high_res_loader = load_loader_stl()\n",
        "    model = SuperResolution().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    writer = SummaryWriter()\n",
        "    n = 0\n",
        "\n",
        "    # Define transforms with legacy interpolation\n",
        "    to_pil = transforms.ToPILImage()\n",
        "    resize = transforms.Resize((48*7, 144*7), interpolation=Image.BICUBIC)\n",
        "    other_resize = transforms.Resize((48*5, 48*5), interpolation=Image.BICUBIC)\n",
        "\n",
        "    for epoch in tqdm(range(500), desc=\"Training\", ncols=120):\n",
        "        for low_res, high_res in zip(low_res_loader, high_res_loader):\n",
        "            # Process batches\n",
        "            low_res_batch = low_res[0].view(-1, 3, 24, 24).to(device)\n",
        "            high_res_batch = high_res[0].view(-1, 3, 96, 96).to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            reconstructed, intermediate = model(low_res_batch)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = nn.MSELoss()(reconstructed, high_res_batch)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Logging and visualization (same as before)\n",
        "            # ... [rest of your original training code] ...\n",
        "\n",
        "        # Save model checkpoint\n",
        "        torch.save(model.state_dict(), '/content/drive/My Drive/isr/isr_best_2.pth')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Start training\n",
        "model = train()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "DataLoader.__init__() got an unexpected keyword argument 'transform'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-70a164ed1799>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-70a164ed1799>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Initialize components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mlow_res_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh_res_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_loader_stl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSuperResolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-44dc60b6c614>\u001b[0m in \u001b[0;36mload_loader_stl\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     low_res_loader = DataLoader(\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: DataLoader.__init__() got an unexpected keyword argument 'transform'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade Pillow"
      ],
      "metadata": {
        "id": "oagYBQDDQgJH",
        "outputId": "7d882207-e49e-4cdc-fd42-69953f87669e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (7.1.1)\n",
            "Collecting Pillow\n",
            "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.1\n",
            "    Uninstalling Pillow-7.1.1:\n",
            "      Successfully uninstalled Pillow-7.1.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires tqdm>=4.64.1, but you have tqdm 4.45.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-11.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "640cfac49a16454dab0a6490f24eda69"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd image-super-resolution"
      ],
      "metadata": {
        "id": "UR-P5SRvEnCC",
        "outputId": "48d6fa06-1a36-455a-8eaf-dcc3c7516b10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/image-super-resolution\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python execute.py --image https://raw.githubusercontent.com/amanshenoy/image-super-resolution/master/results/barbara.bmp --scale 2 --path results/download.png --saved saved/isr_best.pth"
      ],
      "metadata": {
        "id": "2AnZ4wnr_X-c",
        "outputId": "e2bb8def-d970-48ff-fb4b-51f515bfc652",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-07 19:26:50--  https://raw.githubusercontent.com/amanshenoy/image-super-resolution/master/results/barbara.bmp\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1244214 (1.2M) [image/bmp]\n",
            "Saving to: ‘results/download.png’\n",
            "\n",
            "\rresults/download.pn   0%[                    ]       0  --.-KB/s               \rresults/download.pn 100%[===================>]   1.19M  --.-KB/s    in 0.008s  \n",
            "\n",
            "2025-03-07 19:26:50 (155 MB/s) - ‘results/download.png’ saved [1244214/1244214]\n",
            "\n",
            "/content/image-super-resolution/execute.py:136: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(args.saved, map_location={'cuda:0': 'cpu'}))\n",
            "Progressively Scanning: 100%|███████████████████████████████████████| 34/34 [03:20<00:00,  5.90s/it]\n",
            "Channels = 3, Image Shape = 1440 x 1152\n",
            "Image written to results/download_upscaled.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python execute.py --image results/sample1.bmp --scale 2 --saved saved/isr_best.pth"
      ],
      "metadata": {
        "id": "LTeODn6MHHcC",
        "outputId": "693157d7-8794-4ac6-c098-53074d1c3fe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/image-super-resolution/execute.py:136: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(args.saved, map_location={'cuda:0': 'cpu'}))\n",
            "Progressively Scanning: 100%|███████████████████████████████████████| 25/25 [02:19<00:00,  5.57s/it]\n",
            "Channels = 3, Image Shape = 1280 x 854\n",
            "Image written to results/sample1_upscaled.bmp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone repo\n",
        "#!git clone https://github.com/amanshenoy/image-super-resolution.git\n",
        "\n",
        "# Navigate to directory\n",
        "#%cd image-super-resolution\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Restart the runtime if needed (uncomment below)\n",
        "# import os\n",
        "# os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "tfvMeT5yA_Ts",
        "outputId": "63833f08-abbb-408e-cac3-648efbae1e35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Pillow==7.1.1 (from -r requirements.txt (line 1))\n",
            "  Using cached Pillow-7.1.1.tar.gz (38.9 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.20.1+cu124)\n",
            "Collecting tqdm==4.45.0 (from -r requirements.txt (line 4))\n",
            "  Downloading tqdm-4.45.0-py2.py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.7/51.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 2)) (3.0.2)\n",
            "Downloading tqdm-4.45.0-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: Pillow\n",
            "  Building wheel for Pillow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Pillow: filename=Pillow-7.1.1-cp311-cp311-linux_x86_64.whl size=1140060 sha256=7de6291c7b937d80cf59b8fe895e3da58e7a128500c1361eb9e5f8ac9cd37cc9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/9e/8b/9519ca2d058f6b909eddab5f7780d11049aff5050cb21fa606\n",
            "Successfully built Pillow\n",
            "Installing collected packages: tqdm, Pillow, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imageio 2.37.0 requires pillow>=8.3.2, but you have pillow 7.1.1 which is incompatible.\n",
            "scikit-image 0.25.2 requires pillow>=10.1, but you have pillow 7.1.1 which is incompatible.\n",
            "matplotlib 3.10.0 requires pillow>=8, but you have pillow 7.1.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires tqdm>=4.64.1, but you have tqdm 4.45.0 which is incompatible.\n",
            "fastai 2.7.18 requires pillow>=9.0.0, but you have pillow 7.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-7.1.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 tqdm-4.45.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "755c1d7ca6c34f34a858c4e6f1a28957"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ocRkFTf9BEEb"
      }
    }
  ]
}